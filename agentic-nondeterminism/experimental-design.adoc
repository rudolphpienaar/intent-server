== Experimental Design for ChRIS-Based Evaluation

This document sketches an experimental design to instantiate the theoretical framework of the main paper in a concrete system, namely ChRIS. The goal is not to optimize any agent but to empirically illustrate the graph-theoretic claims: that agentic orchestration over a rich tool graph has irreducible hallucination probability, and that an IAS-style architecture collapses that risk surface.

== Overview

We consider two orchestration regimes over the same underlying ChRIS platform:

- An **agentic regime**, in which a large language model (LLM) agent can construct workflows by invoking the ChRIS REST API, plugins, or `chell` in response to high-level clinical intents.
- An **IAS regime**, in which the same LLM can only select from a set of named intents. Each intent is compiled by a deterministic Intent–Action Service (IAS) into a single, prevalidated ChRIS workflow.

For a fixed collection of clinical intents, we run many trials under each regime, log the resulting workflows and their properties, and classify them as valid or invalid according to predefined criteria. These observations provide empirical estimates of the orchestration hallucination probabilities stem:[H_{MCP}(i)] and stem:[H_{IAS}(i)] defined in the main paper.

== ChRIS Context

We assume a standard ChRIS deployment with:

- A set of imaging plugins (e.g., segmentation, registration, diffusion analysis, quality control, visualization).
- A workflow model where plugins are connected via feeds, and inputs/outputs are tracked through the ChRIS data model.
- Accessible orchestration endpoints via the ChRIS REST API and/or the `chell` CLI that allow creating feeds, instantiating plugins, wiring them together, and monitoring execution.

We treat each plugin type as a primitive tool in the sense of the main paper’s graph stem:[G = (V, E)], and each instantiated ChRIS workflow as a path stem:[s \in \mathcal{S}(G)].

== Intents

We define a small but clinically meaningful set of high-level intents. Examples:

- stem:[i_1]: “Segment a brain tumor on T1-weighted MRI and export a quality-control snapshot.”
- stem:[i_2]: “Perform diffusion tensor imaging analysis and generate a tractography visualization.”
- stem:[i_3]: “Run a standardized fMRI preprocessing pipeline and produce motion and signal quality metrics.”
- stem:[i_4]: “Compute volumetric measurements of hippocampal subfields and export a summary report.”

For each intent stem:[i_k], domain experts specify:

- A reference description of required steps (e.g., modality checks, preprocessing, main analysis, QC, export).
- A set stem:[\mathcal{S}^{\star}_{valid}(i_k)] of one or more workflows in the existing ChRIS ecosystem that are considered clinically acceptable for that intent.

This set plays the role of the “gold” subset within stem:[\mathcal{S}_{valid}] for evaluation.

== Regime 1: Agentic Orchestration

=== Setup

In the agentic regime, an LLM agent is configured with the following capabilities:

- Read-only access to ChRIS metadata (available plugins, their parameters, and example usage).
- Write access to create feeds, launch plugins, connect outputs to inputs, and monitor status, either via the REST API or via `chell` commands.
- A textual description of each intent stem:[i_k].

The agent is prompted, for each trial, with the clinical intent description and a brief reminder of available tools. It is allowed to plan and execute an arbitrary workflow that it believes satisfies the intent, subject to basic safety limits (e.g., maximum number of steps, wall-clock timeouts).

=== Trials

For each intent stem:[i_k] we run:

- stem:[N] independent trials, varying prompts and random seeds slightly (e.g., different phrasings, temperature settings) to simulate real usage.

Each trial yields either:

- A realized ChRIS workflow (a sequence of plugin instantiations with parameters and connections).
- Or a failure to construct or execute a workflow (e.g., immediate syntax or API error).

=== Logging

For every trial we log:

- The intent stem:[i_k].
- The full sequence of orchestration actions (plugin types, parameters, connections, and any intermediate errors).
- The final workflow graph as observed in ChRIS (nodes, edges, parameter settings).
- Execution outcome (completed, failed, partial).

This log is then analyzed offline to classify workflows.

=== Classification of Workflows

We define a multi-level classification for each realized workflow stem:[s]:

1. **Syntactic validity**
   - All API calls or `chell` commands are syntactically correct.
   - All required parameters are present and type-correct.
2. **Structural validity**
   - Plugin order respects modality and data dependencies (e.g., segmentation does not precede required registration or preprocessing steps).
   - All mandatory steps for intent stem:[i_k] are present.
   - No illegal cycles or obvious dead-ends in the workflow graph.
3. **Parameter-level semantic validity**
   - Key parameters (e.g., thresholds, anatomical labels, image orientations) are consistent with the intent and with domain best practices.
   - Inputs and outputs are matched to appropriate modalities and patient data.
4. **Clinical acceptability**
   - Domain experts review the workflow and judge whether it belongs to stem:[\mathcal{S}^{\star}_{valid}(i_k)] (or is equivalent up to benign variations), or whether it is clinically unacceptable even if it runs.

We then map each trial to one of:

- **Category A (gold-valid)**: structurally valid, parameter-valid, and judged clinically acceptable (in stem:[\mathcal{S}^{\star}_{valid}(i_k)]).
- **Category B (structurally valid but clinically invalid)**: passes syntactic and structural checks, runs to completion, but is judged clinically unacceptable (e.g., wrong modality, missing a key QC step).
- **Category C (structurally invalid)**: reaches a workflow graph that violates structural constraints (missing mandatory steps, impossible connections).
- **Category D (syntactically invalid)**: fails at the level of API/command syntax or missing parameters.

Categories B, C, and D correspond to different slices of stem:[\mathcal{S}_{invalid}] under the main paper’s notation; Category A corresponds to stem:[\mathcal{S}^{\star}_{valid}(i_k)].

=== Empirical Estimates

For each intent stem:[i_k] we can compute:

- stem:[\hat{H}_{MCP}^{synt}(i_k)] = fraction of trials in Category D.
- stem:[\hat{H}_{MCP}^{struct}(i_k)] = fraction of trials in Category C.
- stem:[\hat{H}_{MCP}^{sem}(i_k)] = fraction of trials in Category B.
- stem:[\hat{H}_{MCP}(i_k)] = 1 minus the fraction of trials in Category A.

These empirical quantities approximate different components of the theoretical hallucination probability stem:[H_{MCP}(i)] and can be analyzed as functions of workflow length stem:[L], number of distinct tools used, and agent prompting strategy.

== Regime 2: IAS-Style Orchestration

=== Setup

In the IAS regime, we introduce a deterministic Intent–Action Service in front of ChRIS:

- The LLM is restricted to selecting one intent stem:[i_k] from a menu or to producing a short natural-language description that is then deterministically mapped to stem:[i_k].
- The IAS implements a mapping stem:[F : I \to \mathcal{S}_{valid}], so that each stem:[i_k] is compiled to a fixed, prevalidated ChRIS workflow stem:[s_k = F(i_k)].
- Execution of stem:[s_k] is performed by ChRIS without any further agentic choice over tools or ordering.

The same intents stem:[\{i_k\}] and the same ChRIS deployment are used as in the agentic regime.

=== Trials

For each intent stem:[i_k] we again run stem:[N] trials in which the LLM is asked to select or phrase the intent, but:

- All trials that map to stem:[i_k] result in the same compiled workflow stem:[s_k].

We log:

- Any variation in intent phrasing.

- Whether the IAS mapping from text to stem:[i_k] is ever incorrect.

=== Classification and Estimates

Because the orchestration is deterministic, the structural and parameter-level classification of stem:[s_k] does not vary across trials:

- If stem:[s_k \in \mathcal{S}^{\star}_{valid}(i_k)], then all successful trials are Category A; orchestration hallucination probability stem:[H_{IAS}(i_k)] is empirically zero by construction.
- If stem:[s_k \notin \mathcal{S}^{\star}_{valid}(i_k)], then the error is attributable to stem:[F] rather than to an agentic policy; this is a mis-specification in the deterministic compiler, not an orchestration hallucination.

We can still measure:

- Misinterpretation rate stem:[\hat{H}_{intent}(i_k)] = fraction of trials in which the LLM selects or is mapped to the wrong intent.

This quantity corresponds to residual uncertainty in the stem:[u \mapsto i] translation rather than to uncertainty in stem:[i \mapsto s].

== Mapping Back to the Theoretical Framework

The experimental measures align with the notation of the main paper as follows:

- The empirical distribution over realized workflows for stem:[i_k] under the agentic regime approximates stem:[\pi_{MCP}(s \mid i_k)].
- The fraction of trials in Categories B, C, and D estimates different components of stem:[H_{MCP}(i_k)], the orchestration hallucination probability for intent stem:[i_k].
- Variation in workflow length stem:[L] and tool count per trial allows us to examine how stem:[\hat{H}_{MCP}(i_k; L)] grows with stem:[L], as suggested by the combinatorial analysis.
- In the IAS regime, stem:[F] enforces a policy stem:[\pi_{IAS}(s \mid i_k)] that is a point mass at stem:[s_k], so that the empirical orchestration hallucination probability stem:[\hat{H}_{IAS}(i_k)] is zero whenever stem:[s_k] is correctly prevalidated.

This design does not aim to exhaustively test all possible workflows in ChRIS. Rather, it provides a concrete, clinically grounded illustration of the theoretical claims: agentic orchestration over a rich tool graph exhibits irreducible hallucination probability even when models are strong and prompts are carefully tuned, whereas IAS-style orchestration collapses that risk surface by construction and confines residual uncertainty to intent interpretation and deterministic compiler correctness.

